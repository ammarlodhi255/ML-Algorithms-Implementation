{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "c04fa79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "e67d3670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3  col4  col5  col6   col7  col8  y\n",
       "0     6   148    72    35     0  33.6  0.627    50  1\n",
       "1     1    85    66    29     0  26.6  0.351    31  0\n",
       "2     8   183    64     0     0  23.3  0.672    32  1\n",
       "3     1    89    66    23    94  28.1  0.167    21  0\n",
       "4     0   137    40    35   168  43.1  2.288    33  1"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\ML Code\\binary_classification_problem\\diabetes.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "65881f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Times Pregnant</th>\n",
       "      <th>Plasma Glucose Concentration</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skinfold thickness</th>\n",
       "      <th>Serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     No. of Times Pregnant  Plasma Glucose Concentration  \\\n",
       "0                        6                           148   \n",
       "1                        1                            85   \n",
       "2                        8                           183   \n",
       "3                        1                            89   \n",
       "4                        0                           137   \n",
       "..                     ...                           ...   \n",
       "763                     10                           101   \n",
       "764                      2                           122   \n",
       "765                      5                           121   \n",
       "766                      1                           126   \n",
       "767                      1                            93   \n",
       "\n",
       "     Diastolic blood pressure  Triceps skinfold thickness  Serum insulin  \\\n",
       "0                          72                          35              0   \n",
       "1                          66                          29              0   \n",
       "2                          64                           0              0   \n",
       "3                          66                          23             94   \n",
       "4                          40                          35            168   \n",
       "..                        ...                         ...            ...   \n",
       "763                        76                          48            180   \n",
       "764                        70                          27              0   \n",
       "765                        72                          23            112   \n",
       "766                        60                           0              0   \n",
       "767                        70                          31              0   \n",
       "\n",
       "     Body mass index  Pedigree function  Age  Class label  \n",
       "0               33.6              0.627   50            1  \n",
       "1               26.6              0.351   31            0  \n",
       "2               23.3              0.672   32            1  \n",
       "3               28.1              0.167   21            0  \n",
       "4               43.1              2.288   33            1  \n",
       "..               ...                ...  ...          ...  \n",
       "763             32.9              0.171   63            0  \n",
       "764             36.8              0.340   27            0  \n",
       "765             26.2              0.245   30            0  \n",
       "766             30.1              0.349   47            1  \n",
       "767             30.4              0.315   23            0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\n",
    "    'No. of Times Pregnant',\n",
    "    'Plasma Glucose Concentration',\n",
    "    'Diastolic blood pressure',\n",
    "    'Triceps skinfold thickness',\n",
    "    'Serum insulin',\n",
    "    'Body mass index',\n",
    "    'Pedigree function',\n",
    "    'Age',\n",
    "    'Class label'\n",
    "]\n",
    "\n",
    "random_state = random.randint(0, 100)\n",
    "df.columns = col_names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "cec0b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Class label']).values\n",
    "y = df['Class label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "37c41977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us handle missing values using a simple imputer with parameters missing_values=0 and strategy=mean\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=0, strategy='mean')\n",
    "imp = imp.fit(X)\n",
    "imputted_data = imp.transform(X)\n",
    "X = imputted_data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "9024b95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Times Pregnant</th>\n",
       "      <th>Plasma Glucose Concentration</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skinfold thickness</th>\n",
       "      <th>Serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Pedigree function</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.494673</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     No. of Times Pregnant  Plasma Glucose Concentration  \\\n",
       "0                 6.000000                         148.0   \n",
       "1                 1.000000                          85.0   \n",
       "2                 8.000000                         183.0   \n",
       "3                 1.000000                          89.0   \n",
       "4                 4.494673                         137.0   \n",
       "..                     ...                           ...   \n",
       "763              10.000000                         101.0   \n",
       "764               2.000000                         122.0   \n",
       "765               5.000000                         121.0   \n",
       "766               1.000000                         126.0   \n",
       "767               1.000000                          93.0   \n",
       "\n",
       "     Diastolic blood pressure  Triceps skinfold thickness  Serum insulin  \\\n",
       "0                        72.0                    35.00000     155.548223   \n",
       "1                        66.0                    29.00000     155.548223   \n",
       "2                        64.0                    29.15342     155.548223   \n",
       "3                        66.0                    23.00000      94.000000   \n",
       "4                        40.0                    35.00000     168.000000   \n",
       "..                        ...                         ...            ...   \n",
       "763                      76.0                    48.00000     180.000000   \n",
       "764                      70.0                    27.00000     155.548223   \n",
       "765                      72.0                    23.00000     112.000000   \n",
       "766                      60.0                    29.15342     155.548223   \n",
       "767                      70.0                    31.00000     155.548223   \n",
       "\n",
       "     Body mass index  Pedigree function   Age  \n",
       "0               33.6              0.627  50.0  \n",
       "1               26.6              0.351  31.0  \n",
       "2               23.3              0.672  32.0  \n",
       "3               28.1              0.167  21.0  \n",
       "4               43.1              2.288  33.0  \n",
       "..               ...                ...   ...  \n",
       "763             32.9              0.171  63.0  \n",
       "764             36.8              0.340  27.0  \n",
       "765             26.2              0.245  30.0  \n",
       "766             30.1              0.349  47.0  \n",
       "767             30.4              0.315  23.0  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The missing values are filled with the mean of the corresponding column\n",
    "\n",
    "pd.DataFrame(imputted_data, columns=df.drop(columns=['Class label']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "99e5338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3125     0.67096774 0.48979592 ... 0.31492843 0.23441503 0.48333333]\n",
      " [0.         0.26451613 0.42857143 ... 0.17177914 0.11656704 0.16666667]\n",
      " [0.4375     0.89677419 0.40816327 ... 0.10429448 0.25362938 0.18333333]\n",
      " ...\n",
      " [0.25       0.49677419 0.48979592 ... 0.16359918 0.07130658 0.15      ]\n",
      " [0.         0.52903226 0.36734694 ... 0.24335378 0.11571307 0.43333333]\n",
      " [0.         0.31612903 0.46938776 ... 0.24948875 0.10119556 0.03333333]]\n"
     ]
    }
   ],
   "source": [
    "# Let us bring the values of all columns on the same scale \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)\n",
    "print(scaled)\n",
    "X = scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "d6665b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (537, 8), X_test: (231, 8), y_train: (537,), y_test: (231,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=random_state, stratify=y)\n",
    "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "d79690ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLEARN'S PERCEPTRON\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "perceptron = Perceptron(max_iter=30, eta0=0.01, random_state=random_state)\n",
    "perceptron.fit(X_train, y_train)\n",
    "y_pred = perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "79103d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Perceptron Accuracy: {round(accuracy_score(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "56dc261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us try different combinations of learning_rate and no_of_iterations:\n",
    "\n",
    "perceptron_accuracies = []\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    for lr in learning_rates:\n",
    "        perceptron = Perceptron(max_iter=iteration, eta0=lr, random_state=random_state)\n",
    "        perceptron.fit(X_train, y_train)\n",
    "        y_pred = perceptron.predict(X_test)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "        perceptron_accuracies.append([iteration, lr, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "df386171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.0001, 0.72],\n",
       " [1, 0.001, 0.72],\n",
       " [1, 0.01, 0.72],\n",
       " [1, 0.1, 0.72],\n",
       " [2, 0.0001, 0.79],\n",
       " [2, 0.001, 0.79],\n",
       " [2, 0.01, 0.79],\n",
       " [2, 0.1, 0.79],\n",
       " [3, 0.0001, 0.79],\n",
       " [3, 0.001, 0.79],\n",
       " [3, 0.01, 0.79],\n",
       " [3, 0.1, 0.79],\n",
       " [4, 0.0001, 0.65],\n",
       " [4, 0.001, 0.65],\n",
       " [4, 0.01, 0.65],\n",
       " [4, 0.1, 0.65],\n",
       " [5, 0.0001, 0.61],\n",
       " [5, 0.001, 0.61],\n",
       " [5, 0.01, 0.61],\n",
       " [5, 0.1, 0.61],\n",
       " [6, 0.0001, 0.76],\n",
       " [6, 0.001, 0.76],\n",
       " [6, 0.01, 0.76],\n",
       " [6, 0.1, 0.76],\n",
       " [7, 0.0001, 0.76],\n",
       " [7, 0.001, 0.76],\n",
       " [7, 0.01, 0.76],\n",
       " [7, 0.1, 0.76],\n",
       " [8, 0.0001, 0.76],\n",
       " [8, 0.001, 0.76],\n",
       " [8, 0.01, 0.76],\n",
       " [8, 0.1, 0.76],\n",
       " [9, 0.0001, 0.76],\n",
       " [9, 0.001, 0.76],\n",
       " [9, 0.01, 0.76],\n",
       " [9, 0.1, 0.76],\n",
       " [10, 0.0001, 0.76],\n",
       " [10, 0.001, 0.76],\n",
       " [10, 0.01, 0.76],\n",
       " [10, 0.1, 0.76],\n",
       " [11, 0.0001, 0.76],\n",
       " [11, 0.001, 0.76],\n",
       " [11, 0.01, 0.76],\n",
       " [11, 0.1, 0.76],\n",
       " [12, 0.0001, 0.76],\n",
       " [12, 0.001, 0.76],\n",
       " [12, 0.01, 0.76],\n",
       " [12, 0.1, 0.76],\n",
       " [13, 0.0001, 0.76],\n",
       " [13, 0.001, 0.76],\n",
       " [13, 0.01, 0.76],\n",
       " [13, 0.1, 0.76],\n",
       " [14, 0.0001, 0.76],\n",
       " [14, 0.001, 0.76],\n",
       " [14, 0.01, 0.76],\n",
       " [14, 0.1, 0.76],\n",
       " [15, 0.0001, 0.76],\n",
       " [15, 0.001, 0.76],\n",
       " [15, 0.01, 0.76],\n",
       " [15, 0.1, 0.76],\n",
       " [16, 0.0001, 0.76],\n",
       " [16, 0.001, 0.76],\n",
       " [16, 0.01, 0.76],\n",
       " [16, 0.1, 0.76],\n",
       " [17, 0.0001, 0.76],\n",
       " [17, 0.001, 0.76],\n",
       " [17, 0.01, 0.76],\n",
       " [17, 0.1, 0.76],\n",
       " [18, 0.0001, 0.76],\n",
       " [18, 0.001, 0.76],\n",
       " [18, 0.01, 0.76],\n",
       " [18, 0.1, 0.76],\n",
       " [19, 0.0001, 0.76],\n",
       " [19, 0.001, 0.76],\n",
       " [19, 0.01, 0.76],\n",
       " [19, 0.1, 0.76],\n",
       " [20, 0.0001, 0.76],\n",
       " [20, 0.001, 0.76],\n",
       " [20, 0.01, 0.76],\n",
       " [20, 0.1, 0.76],\n",
       " [21, 0.0001, 0.76],\n",
       " [21, 0.001, 0.76],\n",
       " [21, 0.01, 0.76],\n",
       " [21, 0.1, 0.76],\n",
       " [22, 0.0001, 0.76],\n",
       " [22, 0.001, 0.76],\n",
       " [22, 0.01, 0.76],\n",
       " [22, 0.1, 0.76],\n",
       " [23, 0.0001, 0.76],\n",
       " [23, 0.001, 0.76],\n",
       " [23, 0.01, 0.76],\n",
       " [23, 0.1, 0.76],\n",
       " [24, 0.0001, 0.76],\n",
       " [24, 0.001, 0.76],\n",
       " [24, 0.01, 0.76],\n",
       " [24, 0.1, 0.76],\n",
       " [25, 0.0001, 0.76],\n",
       " [25, 0.001, 0.76],\n",
       " [25, 0.01, 0.76],\n",
       " [25, 0.1, 0.76],\n",
       " [26, 0.0001, 0.76],\n",
       " [26, 0.001, 0.76],\n",
       " [26, 0.01, 0.76],\n",
       " [26, 0.1, 0.76],\n",
       " [27, 0.0001, 0.76],\n",
       " [27, 0.001, 0.76],\n",
       " [27, 0.01, 0.76],\n",
       " [27, 0.1, 0.76],\n",
       " [28, 0.0001, 0.76],\n",
       " [28, 0.001, 0.76],\n",
       " [28, 0.01, 0.76],\n",
       " [28, 0.1, 0.76],\n",
       " [29, 0.0001, 0.76],\n",
       " [29, 0.001, 0.76],\n",
       " [29, 0.01, 0.76],\n",
       " [29, 0.1, 0.76],\n",
       " [30, 0.0001, 0.76],\n",
       " [30, 0.001, 0.76],\n",
       " [30, 0.01, 0.76],\n",
       " [30, 0.1, 0.76],\n",
       " [31, 0.0001, 0.76],\n",
       " [31, 0.001, 0.76],\n",
       " [31, 0.01, 0.76],\n",
       " [31, 0.1, 0.76],\n",
       " [32, 0.0001, 0.76],\n",
       " [32, 0.001, 0.76],\n",
       " [32, 0.01, 0.76],\n",
       " [32, 0.1, 0.76],\n",
       " [33, 0.0001, 0.76],\n",
       " [33, 0.001, 0.76],\n",
       " [33, 0.01, 0.76],\n",
       " [33, 0.1, 0.76],\n",
       " [34, 0.0001, 0.76],\n",
       " [34, 0.001, 0.76],\n",
       " [34, 0.01, 0.76],\n",
       " [34, 0.1, 0.76],\n",
       " [35, 0.0001, 0.76],\n",
       " [35, 0.001, 0.76],\n",
       " [35, 0.01, 0.76],\n",
       " [35, 0.1, 0.76],\n",
       " [36, 0.0001, 0.76],\n",
       " [36, 0.001, 0.76],\n",
       " [36, 0.01, 0.76],\n",
       " [36, 0.1, 0.76],\n",
       " [37, 0.0001, 0.76],\n",
       " [37, 0.001, 0.76],\n",
       " [37, 0.01, 0.76],\n",
       " [37, 0.1, 0.76],\n",
       " [38, 0.0001, 0.76],\n",
       " [38, 0.001, 0.76],\n",
       " [38, 0.01, 0.76],\n",
       " [38, 0.1, 0.76],\n",
       " [39, 0.0001, 0.76],\n",
       " [39, 0.001, 0.76],\n",
       " [39, 0.01, 0.76],\n",
       " [39, 0.1, 0.76],\n",
       " [40, 0.0001, 0.76],\n",
       " [40, 0.001, 0.76],\n",
       " [40, 0.01, 0.76],\n",
       " [40, 0.1, 0.76],\n",
       " [41, 0.0001, 0.76],\n",
       " [41, 0.001, 0.76],\n",
       " [41, 0.01, 0.76],\n",
       " [41, 0.1, 0.76],\n",
       " [42, 0.0001, 0.76],\n",
       " [42, 0.001, 0.76],\n",
       " [42, 0.01, 0.76],\n",
       " [42, 0.1, 0.76],\n",
       " [43, 0.0001, 0.76],\n",
       " [43, 0.001, 0.76],\n",
       " [43, 0.01, 0.76],\n",
       " [43, 0.1, 0.76],\n",
       " [44, 0.0001, 0.76],\n",
       " [44, 0.001, 0.76],\n",
       " [44, 0.01, 0.76],\n",
       " [44, 0.1, 0.76],\n",
       " [45, 0.0001, 0.76],\n",
       " [45, 0.001, 0.76],\n",
       " [45, 0.01, 0.76],\n",
       " [45, 0.1, 0.76],\n",
       " [46, 0.0001, 0.76],\n",
       " [46, 0.001, 0.76],\n",
       " [46, 0.01, 0.76],\n",
       " [46, 0.1, 0.76],\n",
       " [47, 0.0001, 0.76],\n",
       " [47, 0.001, 0.76],\n",
       " [47, 0.01, 0.76],\n",
       " [47, 0.1, 0.76],\n",
       " [48, 0.0001, 0.76],\n",
       " [48, 0.001, 0.76],\n",
       " [48, 0.01, 0.76],\n",
       " [48, 0.1, 0.76],\n",
       " [49, 0.0001, 0.76],\n",
       " [49, 0.001, 0.76],\n",
       " [49, 0.01, 0.76],\n",
       " [49, 0.1, 0.76],\n",
       " [50, 0.0001, 0.76],\n",
       " [50, 0.001, 0.76],\n",
       " [50, 0.01, 0.76],\n",
       " [50, 0.1, 0.76],\n",
       " [51, 0.0001, 0.76],\n",
       " [51, 0.001, 0.76],\n",
       " [51, 0.01, 0.76],\n",
       " [51, 0.1, 0.76],\n",
       " [52, 0.0001, 0.76],\n",
       " [52, 0.001, 0.76],\n",
       " [52, 0.01, 0.76],\n",
       " [52, 0.1, 0.76],\n",
       " [53, 0.0001, 0.76],\n",
       " [53, 0.001, 0.76],\n",
       " [53, 0.01, 0.76],\n",
       " [53, 0.1, 0.76],\n",
       " [54, 0.0001, 0.76],\n",
       " [54, 0.001, 0.76],\n",
       " [54, 0.01, 0.76],\n",
       " [54, 0.1, 0.76],\n",
       " [55, 0.0001, 0.76],\n",
       " [55, 0.001, 0.76],\n",
       " [55, 0.01, 0.76],\n",
       " [55, 0.1, 0.76],\n",
       " [56, 0.0001, 0.76],\n",
       " [56, 0.001, 0.76],\n",
       " [56, 0.01, 0.76],\n",
       " [56, 0.1, 0.76],\n",
       " [57, 0.0001, 0.76],\n",
       " [57, 0.001, 0.76],\n",
       " [57, 0.01, 0.76],\n",
       " [57, 0.1, 0.76],\n",
       " [58, 0.0001, 0.76],\n",
       " [58, 0.001, 0.76],\n",
       " [58, 0.01, 0.76],\n",
       " [58, 0.1, 0.76],\n",
       " [59, 0.0001, 0.76],\n",
       " [59, 0.001, 0.76],\n",
       " [59, 0.01, 0.76],\n",
       " [59, 0.1, 0.76],\n",
       " [60, 0.0001, 0.76],\n",
       " [60, 0.001, 0.76],\n",
       " [60, 0.01, 0.76],\n",
       " [60, 0.1, 0.76],\n",
       " [61, 0.0001, 0.76],\n",
       " [61, 0.001, 0.76],\n",
       " [61, 0.01, 0.76],\n",
       " [61, 0.1, 0.76],\n",
       " [62, 0.0001, 0.76],\n",
       " [62, 0.001, 0.76],\n",
       " [62, 0.01, 0.76],\n",
       " [62, 0.1, 0.76],\n",
       " [63, 0.0001, 0.76],\n",
       " [63, 0.001, 0.76],\n",
       " [63, 0.01, 0.76],\n",
       " [63, 0.1, 0.76],\n",
       " [64, 0.0001, 0.76],\n",
       " [64, 0.001, 0.76],\n",
       " [64, 0.01, 0.76],\n",
       " [64, 0.1, 0.76],\n",
       " [65, 0.0001, 0.76],\n",
       " [65, 0.001, 0.76],\n",
       " [65, 0.01, 0.76],\n",
       " [65, 0.1, 0.76],\n",
       " [66, 0.0001, 0.76],\n",
       " [66, 0.001, 0.76],\n",
       " [66, 0.01, 0.76],\n",
       " [66, 0.1, 0.76],\n",
       " [67, 0.0001, 0.76],\n",
       " [67, 0.001, 0.76],\n",
       " [67, 0.01, 0.76],\n",
       " [67, 0.1, 0.76],\n",
       " [68, 0.0001, 0.76],\n",
       " [68, 0.001, 0.76],\n",
       " [68, 0.01, 0.76],\n",
       " [68, 0.1, 0.76],\n",
       " [69, 0.0001, 0.76],\n",
       " [69, 0.001, 0.76],\n",
       " [69, 0.01, 0.76],\n",
       " [69, 0.1, 0.76],\n",
       " [70, 0.0001, 0.76],\n",
       " [70, 0.001, 0.76],\n",
       " [70, 0.01, 0.76],\n",
       " [70, 0.1, 0.76],\n",
       " [71, 0.0001, 0.76],\n",
       " [71, 0.001, 0.76],\n",
       " [71, 0.01, 0.76],\n",
       " [71, 0.1, 0.76],\n",
       " [72, 0.0001, 0.76],\n",
       " [72, 0.001, 0.76],\n",
       " [72, 0.01, 0.76],\n",
       " [72, 0.1, 0.76],\n",
       " [73, 0.0001, 0.76],\n",
       " [73, 0.001, 0.76],\n",
       " [73, 0.01, 0.76],\n",
       " [73, 0.1, 0.76],\n",
       " [74, 0.0001, 0.76],\n",
       " [74, 0.001, 0.76],\n",
       " [74, 0.01, 0.76],\n",
       " [74, 0.1, 0.76],\n",
       " [75, 0.0001, 0.76],\n",
       " [75, 0.001, 0.76],\n",
       " [75, 0.01, 0.76],\n",
       " [75, 0.1, 0.76],\n",
       " [76, 0.0001, 0.76],\n",
       " [76, 0.001, 0.76],\n",
       " [76, 0.01, 0.76],\n",
       " [76, 0.1, 0.76],\n",
       " [77, 0.0001, 0.76],\n",
       " [77, 0.001, 0.76],\n",
       " [77, 0.01, 0.76],\n",
       " [77, 0.1, 0.76],\n",
       " [78, 0.0001, 0.76],\n",
       " [78, 0.001, 0.76],\n",
       " [78, 0.01, 0.76],\n",
       " [78, 0.1, 0.76],\n",
       " [79, 0.0001, 0.76],\n",
       " [79, 0.001, 0.76],\n",
       " [79, 0.01, 0.76],\n",
       " [79, 0.1, 0.76],\n",
       " [80, 0.0001, 0.76],\n",
       " [80, 0.001, 0.76],\n",
       " [80, 0.01, 0.76],\n",
       " [80, 0.1, 0.76],\n",
       " [81, 0.0001, 0.76],\n",
       " [81, 0.001, 0.76],\n",
       " [81, 0.01, 0.76],\n",
       " [81, 0.1, 0.76],\n",
       " [82, 0.0001, 0.76],\n",
       " [82, 0.001, 0.76],\n",
       " [82, 0.01, 0.76],\n",
       " [82, 0.1, 0.76],\n",
       " [83, 0.0001, 0.76],\n",
       " [83, 0.001, 0.76],\n",
       " [83, 0.01, 0.76],\n",
       " [83, 0.1, 0.76],\n",
       " [84, 0.0001, 0.76],\n",
       " [84, 0.001, 0.76],\n",
       " [84, 0.01, 0.76],\n",
       " [84, 0.1, 0.76],\n",
       " [85, 0.0001, 0.76],\n",
       " [85, 0.001, 0.76],\n",
       " [85, 0.01, 0.76],\n",
       " [85, 0.1, 0.76],\n",
       " [86, 0.0001, 0.76],\n",
       " [86, 0.001, 0.76],\n",
       " [86, 0.01, 0.76],\n",
       " [86, 0.1, 0.76],\n",
       " [87, 0.0001, 0.76],\n",
       " [87, 0.001, 0.76],\n",
       " [87, 0.01, 0.76],\n",
       " [87, 0.1, 0.76],\n",
       " [88, 0.0001, 0.76],\n",
       " [88, 0.001, 0.76],\n",
       " [88, 0.01, 0.76],\n",
       " [88, 0.1, 0.76],\n",
       " [89, 0.0001, 0.76],\n",
       " [89, 0.001, 0.76],\n",
       " [89, 0.01, 0.76],\n",
       " [89, 0.1, 0.76],\n",
       " [90, 0.0001, 0.76],\n",
       " [90, 0.001, 0.76],\n",
       " [90, 0.01, 0.76],\n",
       " [90, 0.1, 0.76],\n",
       " [91, 0.0001, 0.76],\n",
       " [91, 0.001, 0.76],\n",
       " [91, 0.01, 0.76],\n",
       " [91, 0.1, 0.76],\n",
       " [92, 0.0001, 0.76],\n",
       " [92, 0.001, 0.76],\n",
       " [92, 0.01, 0.76],\n",
       " [92, 0.1, 0.76],\n",
       " [93, 0.0001, 0.76],\n",
       " [93, 0.001, 0.76],\n",
       " [93, 0.01, 0.76],\n",
       " [93, 0.1, 0.76],\n",
       " [94, 0.0001, 0.76],\n",
       " [94, 0.001, 0.76],\n",
       " [94, 0.01, 0.76],\n",
       " [94, 0.1, 0.76],\n",
       " [95, 0.0001, 0.76],\n",
       " [95, 0.001, 0.76],\n",
       " [95, 0.01, 0.76],\n",
       " [95, 0.1, 0.76],\n",
       " [96, 0.0001, 0.76],\n",
       " [96, 0.001, 0.76],\n",
       " [96, 0.01, 0.76],\n",
       " [96, 0.1, 0.76],\n",
       " [97, 0.0001, 0.76],\n",
       " [97, 0.001, 0.76],\n",
       " [97, 0.01, 0.76],\n",
       " [97, 0.1, 0.76],\n",
       " [98, 0.0001, 0.76],\n",
       " [98, 0.001, 0.76],\n",
       " [98, 0.01, 0.76],\n",
       " [98, 0.1, 0.76],\n",
       " [99, 0.0001, 0.76],\n",
       " [99, 0.001, 0.76],\n",
       " [99, 0.01, 0.76],\n",
       " [99, 0.1, 0.76]]"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "3f67bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_accuracy(accuracies):\n",
    "    max_acc = 0\n",
    "    iterations = 0\n",
    "    eta = 0\n",
    "    \n",
    "    for n_iter, lr, acc in accuracies:\n",
    "        if max_acc < acc:\n",
    "            max_acc = acc\n",
    "            iterations = n_iter\n",
    "            eta = lr\n",
    "            \n",
    "    return (iterations, eta, max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "8caeda9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0.0001, 0.79)\n"
     ]
    }
   ],
   "source": [
    "epochs, learning_rate, accuracy = find_best_accuracy(perceptron_accuracies)\n",
    "print((epochs, learning_rate, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "ad828f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "# From the results, it seems that learning_rate = 0.0001 and no_of_iterations = 2, seems to give best results\n",
    "\n",
    "perceptron = Perceptron(max_iter=epochs, eta0=learning_rate, random_state=random_state)\n",
    "perceptron.fit(X_train, y_train)\n",
    "y_pred = perceptron.predict(X_test)\n",
    "perceptron_accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "print(f'Perceptron Accuracy: {perceptron_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "1790e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us display the confusion matrix for perceptron\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def plot_conf_matrix(X_test, y_test, y_pred, classifier, title):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    color = 'black'\n",
    "    matrix = plot_confusion_matrix(classifier, X_test, y_test, cmap=plt.cm.PuBu_r)\n",
    "    matrix.ax_.set_title(title, color=color)\n",
    "    plt.xlabel('Predicted Label', color=color)\n",
    "    plt.ylabel('True Label', color=color)\n",
    "    plt.gcf().axes[0].tick_params(colors=color)\n",
    "    plt.gcf().axes[1].tick_params(colors=color)\n",
    "    plt.show()\n",
    "    \n",
    "plot_conf_matrix(X_test, y_test, y_pred, perceptron, 'Perceptron Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "1d7b52c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report For Perceptron:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.85       150\n",
      "           1       0.83      0.49      0.62        81\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.80      0.72      0.74       231\n",
      "weighted avg       0.80      0.79      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Perceptron\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Classification Report For Perceptron:\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "14f5e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us now use SGD (Adaline with stochastic gradient descent)\n",
    "\n",
    "# Trying different combinations of learning_rate and no_of_iterations:\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_accuracies = []\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    for lr in learning_rates:\n",
    "        sgd = SGDClassifier(max_iter=iteration, eta0=lr, random_state=random_state)\n",
    "        sgd.fit(X_train, y_train)\n",
    "        y_pred = sgd.predict(X_test)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "        sgd_accuracies.append([iteration, lr, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "91300d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.0001, 0.77],\n",
       " [1, 0.001, 0.77],\n",
       " [1, 0.01, 0.77],\n",
       " [1, 0.1, 0.77],\n",
       " [2, 0.0001, 0.66],\n",
       " [2, 0.001, 0.66],\n",
       " [2, 0.01, 0.66],\n",
       " [2, 0.1, 0.66],\n",
       " [3, 0.0001, 0.64],\n",
       " [3, 0.001, 0.64],\n",
       " [3, 0.01, 0.64],\n",
       " [3, 0.1, 0.64],\n",
       " [4, 0.0001, 0.76],\n",
       " [4, 0.001, 0.76],\n",
       " [4, 0.01, 0.76],\n",
       " [4, 0.1, 0.76],\n",
       " [5, 0.0001, 0.6],\n",
       " [5, 0.001, 0.6],\n",
       " [5, 0.01, 0.6],\n",
       " [5, 0.1, 0.6],\n",
       " [6, 0.0001, 0.76],\n",
       " [6, 0.001, 0.76],\n",
       " [6, 0.01, 0.76],\n",
       " [6, 0.1, 0.76],\n",
       " [7, 0.0001, 0.71],\n",
       " [7, 0.001, 0.71],\n",
       " [7, 0.01, 0.71],\n",
       " [7, 0.1, 0.71],\n",
       " [8, 0.0001, 0.78],\n",
       " [8, 0.001, 0.78],\n",
       " [8, 0.01, 0.78],\n",
       " [8, 0.1, 0.78],\n",
       " [9, 0.0001, 0.79],\n",
       " [9, 0.001, 0.79],\n",
       " [9, 0.01, 0.79],\n",
       " [9, 0.1, 0.79],\n",
       " [10, 0.0001, 0.77],\n",
       " [10, 0.001, 0.77],\n",
       " [10, 0.01, 0.77],\n",
       " [10, 0.1, 0.77],\n",
       " [11, 0.0001, 0.77],\n",
       " [11, 0.001, 0.77],\n",
       " [11, 0.01, 0.77],\n",
       " [11, 0.1, 0.77],\n",
       " [12, 0.0001, 0.8],\n",
       " [12, 0.001, 0.8],\n",
       " [12, 0.01, 0.8],\n",
       " [12, 0.1, 0.8],\n",
       " [13, 0.0001, 0.78],\n",
       " [13, 0.001, 0.78],\n",
       " [13, 0.01, 0.78],\n",
       " [13, 0.1, 0.78],\n",
       " [14, 0.0001, 0.79],\n",
       " [14, 0.001, 0.79],\n",
       " [14, 0.01, 0.79],\n",
       " [14, 0.1, 0.79],\n",
       " [15, 0.0001, 0.77],\n",
       " [15, 0.001, 0.77],\n",
       " [15, 0.01, 0.77],\n",
       " [15, 0.1, 0.77],\n",
       " [16, 0.0001, 0.66],\n",
       " [16, 0.001, 0.66],\n",
       " [16, 0.01, 0.66],\n",
       " [16, 0.1, 0.66],\n",
       " [17, 0.0001, 0.74],\n",
       " [17, 0.001, 0.74],\n",
       " [17, 0.01, 0.74],\n",
       " [17, 0.1, 0.74],\n",
       " [18, 0.0001, 0.77],\n",
       " [18, 0.001, 0.77],\n",
       " [18, 0.01, 0.77],\n",
       " [18, 0.1, 0.77],\n",
       " [19, 0.0001, 0.76],\n",
       " [19, 0.001, 0.76],\n",
       " [19, 0.01, 0.76],\n",
       " [19, 0.1, 0.76],\n",
       " [20, 0.0001, 0.68],\n",
       " [20, 0.001, 0.68],\n",
       " [20, 0.01, 0.68],\n",
       " [20, 0.1, 0.68],\n",
       " [21, 0.0001, 0.61],\n",
       " [21, 0.001, 0.61],\n",
       " [21, 0.01, 0.61],\n",
       " [21, 0.1, 0.61],\n",
       " [22, 0.0001, 0.74],\n",
       " [22, 0.001, 0.74],\n",
       " [22, 0.01, 0.74],\n",
       " [22, 0.1, 0.74],\n",
       " [23, 0.0001, 0.61],\n",
       " [23, 0.001, 0.61],\n",
       " [23, 0.01, 0.61],\n",
       " [23, 0.1, 0.61],\n",
       " [24, 0.0001, 0.68],\n",
       " [24, 0.001, 0.68],\n",
       " [24, 0.01, 0.68],\n",
       " [24, 0.1, 0.68],\n",
       " [25, 0.0001, 0.67],\n",
       " [25, 0.001, 0.67],\n",
       " [25, 0.01, 0.67],\n",
       " [25, 0.1, 0.67],\n",
       " [26, 0.0001, 0.7],\n",
       " [26, 0.001, 0.7],\n",
       " [26, 0.01, 0.7],\n",
       " [26, 0.1, 0.7],\n",
       " [27, 0.0001, 0.68],\n",
       " [27, 0.001, 0.68],\n",
       " [27, 0.01, 0.68],\n",
       " [27, 0.1, 0.68],\n",
       " [28, 0.0001, 0.77],\n",
       " [28, 0.001, 0.77],\n",
       " [28, 0.01, 0.77],\n",
       " [28, 0.1, 0.77],\n",
       " [29, 0.0001, 0.77],\n",
       " [29, 0.001, 0.77],\n",
       " [29, 0.01, 0.77],\n",
       " [29, 0.1, 0.77],\n",
       " [30, 0.0001, 0.77],\n",
       " [30, 0.001, 0.77],\n",
       " [30, 0.01, 0.77],\n",
       " [30, 0.1, 0.77],\n",
       " [31, 0.0001, 0.77],\n",
       " [31, 0.001, 0.77],\n",
       " [31, 0.01, 0.77],\n",
       " [31, 0.1, 0.77],\n",
       " [32, 0.0001, 0.77],\n",
       " [32, 0.001, 0.77],\n",
       " [32, 0.01, 0.77],\n",
       " [32, 0.1, 0.77],\n",
       " [33, 0.0001, 0.77],\n",
       " [33, 0.001, 0.77],\n",
       " [33, 0.01, 0.77],\n",
       " [33, 0.1, 0.77],\n",
       " [34, 0.0001, 0.77],\n",
       " [34, 0.001, 0.77],\n",
       " [34, 0.01, 0.77],\n",
       " [34, 0.1, 0.77],\n",
       " [35, 0.0001, 0.77],\n",
       " [35, 0.001, 0.77],\n",
       " [35, 0.01, 0.77],\n",
       " [35, 0.1, 0.77],\n",
       " [36, 0.0001, 0.77],\n",
       " [36, 0.001, 0.77],\n",
       " [36, 0.01, 0.77],\n",
       " [36, 0.1, 0.77],\n",
       " [37, 0.0001, 0.77],\n",
       " [37, 0.001, 0.77],\n",
       " [37, 0.01, 0.77],\n",
       " [37, 0.1, 0.77],\n",
       " [38, 0.0001, 0.77],\n",
       " [38, 0.001, 0.77],\n",
       " [38, 0.01, 0.77],\n",
       " [38, 0.1, 0.77],\n",
       " [39, 0.0001, 0.77],\n",
       " [39, 0.001, 0.77],\n",
       " [39, 0.01, 0.77],\n",
       " [39, 0.1, 0.77],\n",
       " [40, 0.0001, 0.77],\n",
       " [40, 0.001, 0.77],\n",
       " [40, 0.01, 0.77],\n",
       " [40, 0.1, 0.77],\n",
       " [41, 0.0001, 0.77],\n",
       " [41, 0.001, 0.77],\n",
       " [41, 0.01, 0.77],\n",
       " [41, 0.1, 0.77],\n",
       " [42, 0.0001, 0.77],\n",
       " [42, 0.001, 0.77],\n",
       " [42, 0.01, 0.77],\n",
       " [42, 0.1, 0.77],\n",
       " [43, 0.0001, 0.77],\n",
       " [43, 0.001, 0.77],\n",
       " [43, 0.01, 0.77],\n",
       " [43, 0.1, 0.77],\n",
       " [44, 0.0001, 0.77],\n",
       " [44, 0.001, 0.77],\n",
       " [44, 0.01, 0.77],\n",
       " [44, 0.1, 0.77],\n",
       " [45, 0.0001, 0.77],\n",
       " [45, 0.001, 0.77],\n",
       " [45, 0.01, 0.77],\n",
       " [45, 0.1, 0.77],\n",
       " [46, 0.0001, 0.77],\n",
       " [46, 0.001, 0.77],\n",
       " [46, 0.01, 0.77],\n",
       " [46, 0.1, 0.77],\n",
       " [47, 0.0001, 0.77],\n",
       " [47, 0.001, 0.77],\n",
       " [47, 0.01, 0.77],\n",
       " [47, 0.1, 0.77],\n",
       " [48, 0.0001, 0.77],\n",
       " [48, 0.001, 0.77],\n",
       " [48, 0.01, 0.77],\n",
       " [48, 0.1, 0.77],\n",
       " [49, 0.0001, 0.77],\n",
       " [49, 0.001, 0.77],\n",
       " [49, 0.01, 0.77],\n",
       " [49, 0.1, 0.77],\n",
       " [50, 0.0001, 0.77],\n",
       " [50, 0.001, 0.77],\n",
       " [50, 0.01, 0.77],\n",
       " [50, 0.1, 0.77],\n",
       " [51, 0.0001, 0.77],\n",
       " [51, 0.001, 0.77],\n",
       " [51, 0.01, 0.77],\n",
       " [51, 0.1, 0.77],\n",
       " [52, 0.0001, 0.77],\n",
       " [52, 0.001, 0.77],\n",
       " [52, 0.01, 0.77],\n",
       " [52, 0.1, 0.77],\n",
       " [53, 0.0001, 0.77],\n",
       " [53, 0.001, 0.77],\n",
       " [53, 0.01, 0.77],\n",
       " [53, 0.1, 0.77],\n",
       " [54, 0.0001, 0.77],\n",
       " [54, 0.001, 0.77],\n",
       " [54, 0.01, 0.77],\n",
       " [54, 0.1, 0.77],\n",
       " [55, 0.0001, 0.77],\n",
       " [55, 0.001, 0.77],\n",
       " [55, 0.01, 0.77],\n",
       " [55, 0.1, 0.77],\n",
       " [56, 0.0001, 0.77],\n",
       " [56, 0.001, 0.77],\n",
       " [56, 0.01, 0.77],\n",
       " [56, 0.1, 0.77],\n",
       " [57, 0.0001, 0.77],\n",
       " [57, 0.001, 0.77],\n",
       " [57, 0.01, 0.77],\n",
       " [57, 0.1, 0.77],\n",
       " [58, 0.0001, 0.77],\n",
       " [58, 0.001, 0.77],\n",
       " [58, 0.01, 0.77],\n",
       " [58, 0.1, 0.77],\n",
       " [59, 0.0001, 0.77],\n",
       " [59, 0.001, 0.77],\n",
       " [59, 0.01, 0.77],\n",
       " [59, 0.1, 0.77],\n",
       " [60, 0.0001, 0.77],\n",
       " [60, 0.001, 0.77],\n",
       " [60, 0.01, 0.77],\n",
       " [60, 0.1, 0.77],\n",
       " [61, 0.0001, 0.77],\n",
       " [61, 0.001, 0.77],\n",
       " [61, 0.01, 0.77],\n",
       " [61, 0.1, 0.77],\n",
       " [62, 0.0001, 0.77],\n",
       " [62, 0.001, 0.77],\n",
       " [62, 0.01, 0.77],\n",
       " [62, 0.1, 0.77],\n",
       " [63, 0.0001, 0.77],\n",
       " [63, 0.001, 0.77],\n",
       " [63, 0.01, 0.77],\n",
       " [63, 0.1, 0.77],\n",
       " [64, 0.0001, 0.77],\n",
       " [64, 0.001, 0.77],\n",
       " [64, 0.01, 0.77],\n",
       " [64, 0.1, 0.77],\n",
       " [65, 0.0001, 0.77],\n",
       " [65, 0.001, 0.77],\n",
       " [65, 0.01, 0.77],\n",
       " [65, 0.1, 0.77],\n",
       " [66, 0.0001, 0.77],\n",
       " [66, 0.001, 0.77],\n",
       " [66, 0.01, 0.77],\n",
       " [66, 0.1, 0.77],\n",
       " [67, 0.0001, 0.77],\n",
       " [67, 0.001, 0.77],\n",
       " [67, 0.01, 0.77],\n",
       " [67, 0.1, 0.77],\n",
       " [68, 0.0001, 0.77],\n",
       " [68, 0.001, 0.77],\n",
       " [68, 0.01, 0.77],\n",
       " [68, 0.1, 0.77],\n",
       " [69, 0.0001, 0.77],\n",
       " [69, 0.001, 0.77],\n",
       " [69, 0.01, 0.77],\n",
       " [69, 0.1, 0.77],\n",
       " [70, 0.0001, 0.77],\n",
       " [70, 0.001, 0.77],\n",
       " [70, 0.01, 0.77],\n",
       " [70, 0.1, 0.77],\n",
       " [71, 0.0001, 0.77],\n",
       " [71, 0.001, 0.77],\n",
       " [71, 0.01, 0.77],\n",
       " [71, 0.1, 0.77],\n",
       " [72, 0.0001, 0.77],\n",
       " [72, 0.001, 0.77],\n",
       " [72, 0.01, 0.77],\n",
       " [72, 0.1, 0.77],\n",
       " [73, 0.0001, 0.77],\n",
       " [73, 0.001, 0.77],\n",
       " [73, 0.01, 0.77],\n",
       " [73, 0.1, 0.77],\n",
       " [74, 0.0001, 0.77],\n",
       " [74, 0.001, 0.77],\n",
       " [74, 0.01, 0.77],\n",
       " [74, 0.1, 0.77],\n",
       " [75, 0.0001, 0.77],\n",
       " [75, 0.001, 0.77],\n",
       " [75, 0.01, 0.77],\n",
       " [75, 0.1, 0.77],\n",
       " [76, 0.0001, 0.77],\n",
       " [76, 0.001, 0.77],\n",
       " [76, 0.01, 0.77],\n",
       " [76, 0.1, 0.77],\n",
       " [77, 0.0001, 0.77],\n",
       " [77, 0.001, 0.77],\n",
       " [77, 0.01, 0.77],\n",
       " [77, 0.1, 0.77],\n",
       " [78, 0.0001, 0.77],\n",
       " [78, 0.001, 0.77],\n",
       " [78, 0.01, 0.77],\n",
       " [78, 0.1, 0.77],\n",
       " [79, 0.0001, 0.77],\n",
       " [79, 0.001, 0.77],\n",
       " [79, 0.01, 0.77],\n",
       " [79, 0.1, 0.77],\n",
       " [80, 0.0001, 0.77],\n",
       " [80, 0.001, 0.77],\n",
       " [80, 0.01, 0.77],\n",
       " [80, 0.1, 0.77],\n",
       " [81, 0.0001, 0.77],\n",
       " [81, 0.001, 0.77],\n",
       " [81, 0.01, 0.77],\n",
       " [81, 0.1, 0.77],\n",
       " [82, 0.0001, 0.77],\n",
       " [82, 0.001, 0.77],\n",
       " [82, 0.01, 0.77],\n",
       " [82, 0.1, 0.77],\n",
       " [83, 0.0001, 0.77],\n",
       " [83, 0.001, 0.77],\n",
       " [83, 0.01, 0.77],\n",
       " [83, 0.1, 0.77],\n",
       " [84, 0.0001, 0.77],\n",
       " [84, 0.001, 0.77],\n",
       " [84, 0.01, 0.77],\n",
       " [84, 0.1, 0.77],\n",
       " [85, 0.0001, 0.77],\n",
       " [85, 0.001, 0.77],\n",
       " [85, 0.01, 0.77],\n",
       " [85, 0.1, 0.77],\n",
       " [86, 0.0001, 0.77],\n",
       " [86, 0.001, 0.77],\n",
       " [86, 0.01, 0.77],\n",
       " [86, 0.1, 0.77],\n",
       " [87, 0.0001, 0.77],\n",
       " [87, 0.001, 0.77],\n",
       " [87, 0.01, 0.77],\n",
       " [87, 0.1, 0.77],\n",
       " [88, 0.0001, 0.77],\n",
       " [88, 0.001, 0.77],\n",
       " [88, 0.01, 0.77],\n",
       " [88, 0.1, 0.77],\n",
       " [89, 0.0001, 0.77],\n",
       " [89, 0.001, 0.77],\n",
       " [89, 0.01, 0.77],\n",
       " [89, 0.1, 0.77],\n",
       " [90, 0.0001, 0.77],\n",
       " [90, 0.001, 0.77],\n",
       " [90, 0.01, 0.77],\n",
       " [90, 0.1, 0.77],\n",
       " [91, 0.0001, 0.77],\n",
       " [91, 0.001, 0.77],\n",
       " [91, 0.01, 0.77],\n",
       " [91, 0.1, 0.77],\n",
       " [92, 0.0001, 0.77],\n",
       " [92, 0.001, 0.77],\n",
       " [92, 0.01, 0.77],\n",
       " [92, 0.1, 0.77],\n",
       " [93, 0.0001, 0.77],\n",
       " [93, 0.001, 0.77],\n",
       " [93, 0.01, 0.77],\n",
       " [93, 0.1, 0.77],\n",
       " [94, 0.0001, 0.77],\n",
       " [94, 0.001, 0.77],\n",
       " [94, 0.01, 0.77],\n",
       " [94, 0.1, 0.77],\n",
       " [95, 0.0001, 0.77],\n",
       " [95, 0.001, 0.77],\n",
       " [95, 0.01, 0.77],\n",
       " [95, 0.1, 0.77],\n",
       " [96, 0.0001, 0.77],\n",
       " [96, 0.001, 0.77],\n",
       " [96, 0.01, 0.77],\n",
       " [96, 0.1, 0.77],\n",
       " [97, 0.0001, 0.77],\n",
       " [97, 0.001, 0.77],\n",
       " [97, 0.01, 0.77],\n",
       " [97, 0.1, 0.77],\n",
       " [98, 0.0001, 0.77],\n",
       " [98, 0.001, 0.77],\n",
       " [98, 0.01, 0.77],\n",
       " [98, 0.1, 0.77],\n",
       " [99, 0.0001, 0.77],\n",
       " [99, 0.001, 0.77],\n",
       " [99, 0.01, 0.77],\n",
       " [99, 0.1, 0.77]]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "834e3789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 0.0001, 0.8)\n"
     ]
    }
   ],
   "source": [
    "n_iter, lr, acc = find_best_accuracy(sgd_accuracies)\n",
    "print((n_iter, lr, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "15fb4065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# From the results, it seems that learning_rate = 0.01 and no_of_iterations = 7, seems to give best results\n",
    "\n",
    "sgd = SGDClassifier(max_iter=n_iter, eta0=lr, random_state=random_state)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "sgd_accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "print(f'SGD Accuracy: {sgd_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "2ae22f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_matrix(X_test, y_test, y_pred, sgd, 'SGD Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "403b75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report For AdalineSGD:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       150\n",
      "           1       0.81      0.57      0.67        81\n",
      "\n",
      "    accuracy                           0.80       231\n",
      "   macro avg       0.80      0.75      0.76       231\n",
      "weighted avg       0.80      0.80      0.79       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report For AdalineSGD:\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "3bb634de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use logistic regression and try out different optimizers:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "optimizers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "logreg_accuracies = []\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    logreg = LogisticRegression(solver=optimizer, C=1.0, random_state=random_state)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    logreg_accuracies.append(f'Solver: {optimizer}, Accuracy: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "f5999910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Solver: newton-cg, Accuracy: 0.7748917748917749',\n",
       " 'Solver: lbfgs, Accuracy: 0.7748917748917749',\n",
       " 'Solver: liblinear, Accuracy: 0.7792207792207793',\n",
       " 'Solver: sag, Accuracy: 0.7748917748917749',\n",
       " 'Solver: saga, Accuracy: 0.7748917748917749']"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "337ae74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Seems like the optimizer lbfgs seems to out-perform not only the other optimizers but \n",
    "# also the previous algorithms in terms of accuracy\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', C=1.0, random_state=random_state)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "logreg_accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "print(f'Logreg Accuracy: {logreg_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "730a62f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_matrix(X_test, y_test, y_pred, logreg, 'Logreg Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "e9f68aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report For Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       150\n",
      "           1       0.71      0.60      0.65        81\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.76      0.74      0.74       231\n",
      "weighted avg       0.77      0.77      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report For Logistic Regression:\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "388d8555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Accuracy: 0.79\n",
      "SGD(Adaline) Accuracy: 0.8\n",
      "Logreg Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Here is the accuracy for each algorithm:\n",
    "\n",
    "print(f'Perceptron Accuracy: {perceptron_accuracy}')\n",
    "print(f'SGD(Adaline) Accuracy: {sgd_accuracy}')\n",
    "print(f'Logreg Accuracy: {logreg_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems that Adaline SGD beats both Perceptron and Logistic Regression in terms of accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
